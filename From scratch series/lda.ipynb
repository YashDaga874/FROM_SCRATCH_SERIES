{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\From scratch series\\LDA\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20967</th>\n",
       "      <td>20968</td>\n",
       "      <td>Contemporary machine learning: a guide for pra...</td>\n",
       "      <td>Machine learning is finding increasingly bro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>20969</td>\n",
       "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
       "      <td>Polycrystalline diamond coatings have been g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>20970</td>\n",
       "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
       "      <td>We present a new approach for identifying si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>20971</td>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>20972</td>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20972 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TITLE  \\\n",
       "0          1        Reconstructing Subject-Specific Effect Maps   \n",
       "1          2                 Rotation Invariance Neural Network   \n",
       "2          3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3          4  A finite element approximation for the stochas...   \n",
       "4          5  Comparative study of Discrete Wavelet Transfor...   \n",
       "...      ...                                                ...   \n",
       "20967  20968  Contemporary machine learning: a guide for pra...   \n",
       "20968  20969  Uniform diamond coatings on WC-Co hard alloy c...   \n",
       "20969  20970  Analysing Soccer Games with Clustering and Con...   \n",
       "20970  20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "20971  20972   Why optional stopping is a problem for Bayesians   \n",
       "\n",
       "                                                ABSTRACT  Computer Science  \\\n",
       "0        Predictive models allow subject-specific inf...                 1   \n",
       "1        Rotation invariance and translation invarian...                 1   \n",
       "2        We introduce and develop the notion of spher...                 0   \n",
       "3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "...                                                  ...               ...   \n",
       "20967    Machine learning is finding increasingly bro...                 1   \n",
       "20968    Polycrystalline diamond coatings have been g...                 0   \n",
       "20969    We present a new approach for identifying si...                 1   \n",
       "20970    The sum of Log-normal variates is encountere...                 0   \n",
       "20971    Recently, optional stopping has been a subje...                 0   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0            0            0           0                     0   \n",
       "1            0            0           0                     0   \n",
       "2            0            1           0                     0   \n",
       "3            0            1           0                     0   \n",
       "4            0            0           1                     0   \n",
       "...        ...          ...         ...                   ...   \n",
       "20967        1            0           0                     0   \n",
       "20968        1            0           0                     0   \n",
       "20969        0            0           0                     0   \n",
       "20970        0            1           1                     0   \n",
       "20971        0            1           1                     0   \n",
       "\n",
       "       Quantitative Finance  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "...                     ...  \n",
       "20967                     0  \n",
       "20968                     0  \n",
       "20969                     0  \n",
       "20970                     0  \n",
       "20971                     0  \n",
       "\n",
       "[20972 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\yashd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yashd\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yashd\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB 960.0 kB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/11.5 MB 1.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/11.5 MB 3.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/11.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.4/11.5 MB 4.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.5 MB 6.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.8/11.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.5/11.5 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.4/11.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.5/11.5 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.3/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.5 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.5 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.5 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "   ---------------------------------------- 0.0/507.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 507.9/507.9 kB 15.6 MB/s eta 0:00:00\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 0.0/346.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 346.8/346.8 kB 21.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirichlet, hyperparams, tokenizer\n",
    "ALPHA = 0.1\n",
    "BETA = 0.1\n",
    "NUM_TOPICS = 20 #COHERENCE SCORE AND SEE HOW MANY YOU COULD NEED\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequencies(data, max_docs = 10000):\n",
    "    freqs = Counter()\n",
    "    all_stopwords = sp.Default.stop_words\n",
    "    all_stopwords.add(\"enron\")\n",
    "    nr_tokens = 0\n",
    "\n",
    "    for doc in data[:max_docs]:\n",
    "        tokens = sp.tokenizer(doc)\n",
    "        for token in tokens:\n",
    "            token_text = token.text.lower()\n",
    "            if token_text not in all_stopwords and token.is_alpha:\n",
    "                nr_tokens += 1\n",
    "                freqs[token_text] += 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "\n",
    "def get_vocab(freqs, freq_threshold = 3):\n",
    "    vocab  = {}\n",
    "    vocab_idx_str = {}\n",
    "    vocab_idx = 0\n",
    "\n",
    "    for word in freqs:\n",
    "        if freqs[word] >= freq_threshold:\n",
    "            vocab[word] = vocab_idx\n",
    "            vocab_idx_str[vocab_idx] = word\n",
    "            vocab_idx += 1\n",
    "    return vocab, vocab_idx_str\n",
    "         \n",
    "\n",
    "def tokenize_dataset(data, vocab, max_docs = 10000):\n",
    "    nr_tokens = 0\n",
    "    nr_docs = 0\n",
    "    docs = []\n",
    "    for doc in data[:max_docs]:\n",
    "        tokens = sp.tokenizer(doc)\n",
    "\n",
    "        if len(tokens) > 1:\n",
    "            doc = []\n",
    "            for token in tokens:\n",
    "                token_text = token.text.lower()\n",
    "                if token_text in vocab:\n",
    "                    doc.append(token_text)\n",
    "                    nr_tokens += 1\n",
    "            nr_docs += 1\n",
    "            docs.append(doc)\n",
    "\n",
    "    print(f\"Number of emails: {nr_docs}\")\n",
    "    print(f\"Number of tokens: {nr_tokens}\")\n",
    "\n",
    "    #Numericalize \n",
    "\n",
    "    corpus = []\n",
    "    for doc in docs:\n",
    "        corpus_d = []\n",
    "\n",
    "        for token in doc:\n",
    "            corpus.append(vocab[token])\n",
    "\n",
    "        corpus.append(np.asarray(corpus_d))\n",
    "\n",
    "    return docs, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails_messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['message_text'].sample(frac = 0.5, random_state = 42).values\n",
    "freqs = generate_frequencies(data)\n",
    "vocab, vocab_idx_str = get_vocab(freqs)\n",
    "docs, corpus = tokenize_dataset(data, vocab)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_collapsed_Gibbs(corpus, num_iter = 200):\n",
    "    # INITIALIZING COUNTS AND Z\n",
    "    Z = []\n",
    "    num_docs = len(corpus)\n",
    "\n",
    "    for doc_idx, doc in enumerate(corpus):\n",
    "        Zd = np.random.randint(low = 0, high = NUM_TOPICS, size = len(doc))\n",
    "        Z.append(Zd)\n",
    "\n",
    "    ndk = np.zeroes((num_docs, NUM_TOPICS))\n",
    "    for d in range(num_docs):\n",
    "        for k in range(NUM_TOPICS):\n",
    "            ndk[d,k] = np.sum(Z[d] == k)\n",
    "\n",
    "    nkw = np.zeroes((NUM_TOPICS, vocab_size))\n",
    "    for doc_idx, doc in enumerate(corpus):\n",
    "        for i, word in enumerate(doc):\n",
    "            topic = Z[doc_idx][i]\n",
    "            nkw[topic, word] += 1\n",
    "\n",
    "    nk = np.sum(nkw, axis = 1)\n",
    "    topic_list = [i for i in range(NUM_TOPICS)]\n",
    "\n",
    "    for _ in tqdm(range(num_iter)):\n",
    "        for doc_idx, doc in enumerate(corpus):\n",
    "            for i in range(len(doc)):\n",
    "                word = doc[i]\n",
    "                topic = Z[doc_idx][i]\n",
    "\n",
    "                #removing Z_i because conditioned on Z_(-i)\n",
    "                ndk[doc_idx, topic] -= 1\n",
    "                nkw[topic, word] -= 1\n",
    "                nk[topic] -= 1\n",
    "\n",
    "                p_z = (ndk[doc_idx, :] + ALPHA) * (nkw[:, word] + BETA) / (nk[:] + BETA*vocab_size)\n",
    "                topic = random.choices(topic_list, weights = p_z, k=1)[0]\n",
    "\n",
    "\n",
    "                #update the n paramtrs\n",
    "                Z[doc_idx][i] = topic\n",
    "                ndk[doc_idx, topic] += 1\n",
    "                nkw[topic, word] += 1\n",
    "                nk[topic] += 1\n",
    "\n",
    "    return Z, ndk, nkw, nk\n",
    "\n",
    "Z, ndk, nkw, nk = LDA_collapsed_Gibbs(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = nkw / nk.reshape(NUM_TOPICS, 1)\n",
    "\n",
    "num_words = 10\n",
    "\n",
    "for k in range(NUM_TOPICS):\n",
    "    most_common_words = np.argsort(phi[k])[::-1][:num_words]\n",
    "    print(f\"Topic {k} and its most common words are: \")\n",
    "\n",
    "    for word in most_common_words:\n",
    "        print(vocab_idx_str[word])\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
